{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\P52s\\\\Documents\\\\Python Project\\\\SpellX'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\") \n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellX.utils.trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the probability of introducing artificial spelling errors in training data.\n",
    "error_rate = 0.8\n",
    "\n",
    "# Define the size of the hidden state in the LSTM layers.\n",
    "hidden_size = 256\n",
    "\n",
    "# Define the number of training epochs.\n",
    "nb_epochs = 100\n",
    "\n",
    "# Define batch sizes for training and validation.\n",
    "train_batch_size = 128\n",
    "val_batch_size = 256\n",
    "\n",
    "# Choose the sampling mode for decoding sequences.\n",
    "# It can be 'argmax' or 'multinomial'.\n",
    "sample_mode = 'argmax'\n",
    "\n",
    "# Choose whether to reverse input sequences before training.\n",
    "reverse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './artifacts/data_ingestion/data/train/'\n",
    "train_books= ['big.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = './artifacts/data_ingestion/data/validation/'\n",
    "val_books=['spell-testset1.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'artifacts/data_ingestion/data/test/'\n",
    "test_books=['spell-testset2.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_data (InputLayer)       [(None, None, 55)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm_1 (LSTM)           (None, None, 256)    319488      encoder_data[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_data (InputLayer)       [(None, None, 56)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm_2 (LSTM)           [(None, 256), (None, 525312      encoder_lstm_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  320512      decoder_data[0][0]               \n",
      "                                                                 encoder_lstm_2[0][1]             \n",
      "                                                                 encoder_lstm_2[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_softmax (Dense)         (None, None, 56)     14392       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,179,704\n",
      "Trainable params: 1,179,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_path = 'research/lstm_epoch_100.h5'\n",
    "loaded_model = load_model(pretrained_model_path, custom_objects={\n",
    "    'truncated_acc': truncated_acc, 'truncated_loss': truncated_loss\n",
    "})\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellX.utils.CharacterTable import CharacterTable\n",
    "\n",
    "text = read_text(val_path, val_books)\n",
    "vocab = tokenize(text)\n",
    "vocab = list(filter(None, set(vocab)))\n",
    "\n",
    "maxlen = max([len(token) for token in vocab]) + 2\n",
    "val_encoder, val_decoder, val_target = transform(\n",
    "    vocab, maxlen, error_rate=error_rate, shuffle=False)\n",
    "\n",
    "input_chars = set(' '.join(val_encoder))\n",
    "target_chars = set(' '.join(val_decoder))\n",
    "\n",
    "input_ctable = CharacterTable(input_chars)\n",
    "target_ctable = CharacterTable(target_chars)\n",
    "train_steps = len(vocab) // train_batch_size\n",
    "val_steps = len(val_tokens) // val_batch_size\n",
    "\n",
    "# Entraînement et évaluation.\n",
    "text = read_text(val_path, val_books)\n",
    "vocab = tokenize(text)\n",
    "vocab = list(filter(None, set(vocab)))\n",
    "\n",
    "maxlen = max([len(token) for token in vocab]) + 2\n",
    "val_encoder, val_decoder, val_target = transform(\n",
    "    vocab, maxlen, error_rate=error_rate, shuffle=False)\n",
    "\n",
    "input_chars = set(' '.join(val_encoder))\n",
    "target_chars = set(' '.join(val_decoder))\n",
    "nb_input_chars = len(input_chars)\n",
    "nb_target_chars = len(target_chars)\n",
    "\n",
    "\n",
    "# Compile the model.\n",
    "model, encoder_model, decoder_model = seq2seq(\n",
    "    hidden_size, nb_input_chars, nb_target_chars)\n",
    "print(model.summary())\n",
    "# Listes pour stocker l'historique d'entraînement\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "val_loss_history = []\n",
    "val_accuracy_history = []\n",
    "\n",
    "# Boucle à travers chaque époque\n",
    "for epoch in range(nb_epochs):\n",
    "    print('Époque principale {:d}/{:d}'.format(epoch + 1, nb_epochs))\n",
    "    \n",
    "    # Transformer les données d'entraînement en introduisant des erreurs d'orthographe\n",
    "    train_encoder, train_decoder, train_target = transform(\n",
    "        vocab, maxlen, error_rate=error_rate, shuffle=True)\n",
    "        \n",
    "    # Générer des lots de données d'entraînement et de validation\n",
    "    train_encoder_batch = batch(train_encoder, maxlen, input_ctable,\n",
    "                                train_batch_size, reverse)\n",
    "    train_decoder_batch = batch(train_decoder, maxlen, target_ctable,\n",
    "                                train_batch_size)\n",
    "    train_target_batch = batch(train_target, maxlen, target_ctable,\n",
    "                               train_batch_size)    \n",
    "\n",
    "    val_encoder_batch = batch(val_encoder, maxlen, input_ctable,\n",
    "                              val_batch_size, reverse)\n",
    "    val_decoder_batch = batch(val_decoder, maxlen, target_ctable,\n",
    "                              val_batch_size)\n",
    "    val_target_batch = batch(val_target, maxlen, target_ctable,\n",
    "                             val_batch_size)\n",
    "    \n",
    "    # Préparer les générateurs de données pour l'entraînement et la validation\n",
    "    train_loader = datagen(train_encoder_batch,\n",
    "                           train_decoder_batch, train_target_batch)\n",
    "    val_loader = datagen(val_encoder_batch,\n",
    "                         val_decoder_batch, val_target_batch)\n",
    "    \n",
    "    # Entraîner le modèle pendant une époque\n",
    "    history = model.fit(train_loader,\n",
    "                        steps_per_epoch=train_steps,\n",
    "                        epochs=1, verbose=1, \n",
    "                        validation_data=val_loader,\n",
    "                        validation_steps=val_steps)\n",
    "    \n",
    "    # Ajouter l'historique d'entraînement pour la perte et la précision\n",
    "    train_loss_history.append(history.history['loss'][0])\n",
    "    train_accuracy_history.append(history.history['accuracy'][0])\n",
    "    val_loss_history.append(history.history['val_loss'][0])\n",
    "    val_accuracy_history.append(history.history['val_accuracy'][0])\n",
    "\n",
    "    # À la fin de l'époque, décoder un lot de jetons mal orthographiés\n",
    "    # du jeu de validation pour visualiser les performances du modèle.\n",
    "    nb_tokens = 5\n",
    "    input_tokens, target_tokens, decoded_tokens = decode_sequences(\n",
    "        val_encoder, val_target, input_ctable, target_ctable,\n",
    "        maxlen, reverse, encoder_model, decoder_model, nb_tokens,\n",
    "        sample_mode=sample_mode, random=True)\n",
    "        \n",
    "    print('-')\n",
    "    print('Jetons d''entrée:  ', input_tokens)\n",
    "    print('Jetons décodés:', decoded_tokens)\n",
    "    print('Jetons cibles: ', target_tokens)\n",
    "    print('-')\n",
    "        \n",
    "    # Enregistrer le modèle à la fin de chaque époque.\n",
    "    model_file = '_'.join(['lstm', 'epoch', str(epoch + 1)]) + '.h5'\n",
    "    save_dir = 'artifacts/Model Training/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_path = os.path.join(save_dir, model_file)\n",
    "    print('Enregistrement du modèle complet à {:s}'.format(save_path))\n",
    "    model.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test vocabulary size = 406\n",
      "Number of unique input characters: 51\n",
      "Number of unique target characters: 29\n",
      "Max sequence length in the test set: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\P52s\\.conda\\envs\\chat\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_data (InputLayer)       [(None, None, 51)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm_1 (LSTM)           (None, None, 256)    315392      encoder_data[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_data (InputLayer)       [(None, None, 29)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm_2 (LSTM)           [(None, 256), (None, 525312      encoder_lstm_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  292864      decoder_data[0][0]               \n",
      "                                                                 encoder_lstm_2[0][1]             \n",
      "                                                                 encoder_lstm_2[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_softmax (Dense)         (None, None, 29)     7453        decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,141,021\n",
      "Trainable params: 1,141,021\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Entrée: lonfes\n",
      "Cible: lones\n",
      "Décodé: ffffppddffveekeefee\n",
      "------------------------------\n",
      "Entrée: compir\n",
      "Cible: compair\n",
      "Décodé: jfffpddffveekeefeee\n",
      "------------------------------\n",
      "Entrée: magnirecent\n",
      "Cible: magnifecent\n",
      "Décodé: fffveekefeekeeeeeee\n",
      "------------------------------\n",
      "Entrée: parralel\n",
      "Cible: parralell\n",
      "Décodé: ffffvekeekefeeeeeee\n",
      "------------------------------\n",
      "Entrée: pHlaned\n",
      "Cible: planed\n",
      "Décodé: ffffveekefeekeeeeee\n",
      "------------------------------\n",
      "Entrée: neccesayr\n",
      "Cible: neccesary\n",
      "Décodé: fffppddffveekeefeee\n",
      "------------------------------\n",
      "Entrée: reciVet\n",
      "Cible: reciet\n",
      "Décodé: u ffffboornnssborrn\n",
      "------------------------------\n",
      "Entrée: neccasariy\n",
      "Cible: neccasary\n",
      "Décodé: fffvekefeekeeeeeeee\n",
      "------------------------------\n",
      "Entrée: ofen\n",
      "Cible: offen\n",
      "Décodé: fffppddffveekefeeek\n",
      "------------------------------\n",
      "Entrée: promblem\n",
      "Cible: promblem\n",
      "Décodé: ffffpkffveekeeekeee\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "text = read_text(test_path, test_books)\n",
    "vocab = tokenize(text)\n",
    "vocab = list(filter(None, set(vocab)))\n",
    "\n",
    "maxlen = max([len(token) for token in vocab]) + 2\n",
    "test_encoder, test_decoder, test_target = transform(\n",
    "    vocab, maxlen, error_rate=error_rate, shuffle=False)\n",
    "\n",
    "input_chars = set(' '.join(test_encoder))\n",
    "target_chars = set(' '.join(test_decoder))\n",
    "nb_input_chars = len(input_chars)\n",
    "nb_target_chars = len(target_chars)\n",
    "\n",
    "print('Test vocabulary size =', len(vocab))\n",
    "print('Number of unique input characters:', nb_input_chars)\n",
    "print('Number of unique target characters:', nb_target_chars)\n",
    "print('Max sequence length in the test set:', maxlen)\n",
    "\n",
    "# Compile the model.\n",
    "model, encoder_model, decoder_model = seq2seq(\n",
    "    hidden_size, nb_input_chars, nb_target_chars)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "from spellX.utils.CharacterTable import CharacterTable\n",
    "\n",
    "input_ctable = CharacterTable(input_chars)\n",
    "target_ctable = CharacterTable(target_chars)\n",
    "\n",
    "\n",
    "nb_tokens = 10  # Nombre de séquences à décoder et imprimer\n",
    "\n",
    "# Décoder et imprimer un nombre donné de séquences du jeu de test\n",
    "input_tokens, target_tokens, decoded_tokens = decode_sequences(\n",
    "    test_encoder, test_target, input_ctable, target_ctable,\n",
    "    maxlen, reverse, encoder_model, decoder_model, nb_tokens,\n",
    "    sample_mode=sample_mode, random=True)\n",
    "\n",
    "# Parcourir les séquences décodées et afficher les entrées, cibles et décodages\n",
    "for i in range(nb_tokens):\n",
    "    print('Entrée:', input_tokens[i])\n",
    "    print('Cible:', target_tokens[i])\n",
    "    print('Décodé:', decoded_tokens[i])\n",
    "    print('-' * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
